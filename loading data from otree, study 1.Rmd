---
title: "testing similarity data"
author: "Christian Stenbro"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load/install packages}
pacman::p_load(tidyverse,
               rjson,
               rethinking,
               viridis)
```

# 1. Preprocessing

## 1.1 Reading data and removing empty columns / excluding participants with missing data

```{r}
# reading pilot data
data <- read_csv("/Users/christianstenbro/AU/eSYMb/Similarity Rating Exp/Pilot/otree_data_07_07_2025/SimilarityRatingExperiment_2025-07-07.csv")

# loading otree page time data
pagetimes <- read_csv("/Users/christianstenbro/AU/eSYMb/Similarity Rating Exp/Pilot/otree_data_07_07_2025/PageTimes-2025-07-07.csv")
```

```{r}
# filtering out non-participant rows
data <- data %>% filter(participant.label != "NA")
pagetimes <- pagetimes %>% filter(participant_code != "NA")
```

```{r}
# checking out the variable names
cat("rating data columns:", "\n")
colnames(data)
cat("pagetime columns:","\n")
colnames(pagetimes)
```

```{r}
# extract participant.id_in_session of participants who did not reach the goodbye page (page 37)
incomplete_list <- data %>% filter(participant._index_in_pages != 37) %>% 
  distinct(participant.id_in_session) %>% 
  pull(participant.id_in_session)

length(incomplete_list)

# this list contains participant.id_in_session for participants who did not complete the study
incomplete_list

# exclude participants who did not complete the experiment missing data
data <- data %>% filter(!participant.id_in_session %in% incomplete_list)
```

**The session IDs in the 'incomplete_list' are important, as the stim-set keys corresponding to these IDs will need to be re-rated**

```{r}
# making lists of participant codes/labels
participant_label_list <- unique(data$participant.label)
participant_id_in_session_list <- unique(data$participant.id_in_session)
participant_code_list <- unique(data$participant.code)
```

```{r}
# visualising the ratio
num_incomplete <- length(incomplete_list)
num_complete <- length(participant_id_in_session_list)

# Two values to compare
values <- c(num_incomplete, num_complete)

# Names for each bar
names(values) <- c("Did not complete", "Completed")



# Simple bar plot
bar_positions <- barplot(values,
        main = "Participant completion status",
        sub = paste("Keys for sets that need new ratings:", paste(incomplete_list, collapse = ", ")),
        col = c("skyblue", "orange"),
        ylab = "Count",
        ylim = c(0, max(values) * 1.2))
text(x = bar_positions, 
     y = values, 
     labels = values, 
     pos = 3,         
     cex = 0.9,       
     col = "black")
```

## 1.2 Defining functions to extract variables from the rating data ('data' object)

```{r}
organize_data <- function(ID_number) {
  
  ID <- participant_label_list[ID_number]
  print(ID)
  
  subset <- data %>% filter(participant.label == ID)
  
  # setting up constants
  rounds <- c(1,3,5)
  
  # unpacking the JSON lists
  image_indices <- list()
  image_ratings <- list()
  rating_times <- list()
  is_attention_check <- list()
  stim_indices <- list()
  file_names <- list()
  study_number <- list()
  round_number <- list()
  participant_label <- list()
  participant_code <- list()
  
  for (i in rounds) {
    image_indices <- append(image_indices, list(fromJSON(subset$player.imageIndices[i])))
    image_ratings <- append(image_ratings, list(fromJSON(subset$player.imageRatings[i])))
    rating_times <- append(rating_times, list(fromJSON(subset$player.ratingTimes[i])))
    is_attention_check <- append(is_attention_check, list(fromJSON(subset$player.isAttentionCheck[i])))
    stim_indices <- append(stim_indices, list(fromJSON(subset$player.stimIndices[i])))
    file_names <- append(file_names, list(fromJSON(subset$player.originalFileName[i])))
    study_number <- append(study_number, list(fromJSON(subset$player.sessionStudyNumber[i])))
    
    # adding round number
    set_size <- length(fromJSON(subset$player.imageIndices[i]))
    round_idx_vector <- rep(i, set_size)
    round_number <- append(round_number, round_idx_vector)
    
    # adding variables that should be repeated for all trials
    participant_label <- append(participant_label, rep(participant_label_list[ID_number], set_size))
    participant_code <- append(participant_code, rep(participant_code_list[ID_number], set_size))
    
  }
  
  #unpacking lists
  image_indices <- unlist(image_indices)
  image_ratings <- unlist(image_ratings)
  rating_times <- unlist(rating_times)
  is_attention_check <- unlist(is_attention_check)
  stim_indices <- unlist(stim_indices)
  file_names <- unlist(file_names)
  study_number <- unlist(study_number)
  round_number <- unlist(round_number)
  participant_label <- unlist(participant_label)
  participant_code <- unlist(participant_code)
  #attention_check_status <- unlist(attention_check_status)
  
  # making a new data base for visualisation purposes
  subset_unpacked <- data_frame(image_indices,
                                image_ratings,
                                rating_times,
                                is_attention_check,
                                stim_indices,
                                file_names,
                                study_number,
                                round_number,
                                participant_label,
                                participant_code)
                                #attention_check_status)
  
  # making a single object containing the attention check status variable
  attention_check_status <- list()
  
  for (i in rounds) {
    attention_check_status <- append(attention_check_status, list(fromJSON(subset$player.withinExpectedRatingRange[i])))
  }
  
  attention_check_status <- unlist(unlist(attention_check_status))
  
  return(list(subset_unpacked = subset_unpacked, 
              attention_check_status = attention_check_status)
         )
}
```

Making a function to append attention checks to the participant subset (relies on the previous function):

```{r}
subset_with_attention_check_status <- function(ID_number) {
  
  temp_data <- organize_data(ID_number)
  
  # getting the indices for the att. checks
  att_checks_indices <- temp_data$subset_unpacked$image_indices[temp_data$subset_unpacked$is_attention_check == TRUE]
  
  # cleaning the attention check pass fail variable to only contain TRUE / FALSE
  attention_check_status_clean <- grep("^(TRUE|FALSE)$", temp_data$attention_check_status, value = TRUE)
  
  # extracting attention check type
  attention_check_type <- grep("^(high|low)$", temp_data$attention_check_status, value = TRUE)
  
  # extracting full string
  full_string <- temp_data$attention_check_status 
  grouped <- split(full_string, ceiling(seq_along(full_string) / 3))
  collapsed <- sapply(grouped, paste, collapse = " ")
  attention_check_status_full_string <- unname(collapsed)
  
  # combining into a new table alongside the att. check indices
  attention_check_status_tibble <- tibble(attention_check_status_clean, 
                                          attention_check_status_full_string, 
                                          attention_check_type, 
                                          att_checks_indices)
  
  # merging this with the organized data frame
  subset_complete <- merge(temp_data$subset_unpacked, attention_check_status_tibble, by.x = "image_indices", by.y = "att_checks_indices", all=T)
 
  return(subset_complete)
}
```

## 1.3 Applying functions to create the 'grand data frame'

The final step is to stitch together a new grand data frame from the subsets created with the subset_with_attention_check_status() function:

```{r}
# setting up constants
participants <- c(1:length(participant_label_list))

# setting up empty data frame
df <- data_frame()

# looping
for (i in participants) {
  temp_subset <- subset_with_attention_check_status(i)
  sequential_ID <- rep(i, nrow(temp_subset))
  temp_subset$sequential_ID <- sequential_ID
  df <- rbind(df, temp_subset)
}

# adding attention check pass / fail status
att_check_subset <- df %>% filter(is_attention_check == TRUE) %>% group_by(sequential_ID) %>% summarise(
    passed_checks = sum(attention_check_status_clean == TRUE, na.rm = TRUE),
    failed_checks = sum(attention_check_status_clean == FALSE, na.rm = TRUE))

# merge this with the dataframe
df <- merge(df, att_check_subset, by = 'sequential_ID', all.x = T)
```

## 1.4 Extracting comments and merging with the data frame

```{r}
participant_label_list == df %>% distinct(participant_label)

# extracting non-NA comments from participants who completed the study
comment_subset <- data %>% filter(participant.label %in% participant_label_list) %>% 
  select(participant.label, player.technicalIssues, player.dataValidity)

comment_subset <- comment_subset %>% 
  filter(!is.na(player.technicalIssues) | !is.na(player.dataValidity)) %>% 
  rename("participant_label" = participant.label,
         "com_tech_issues" = player.technicalIssues, 
         "com_data_validity" = player.dataValidity)

# merging with data frame by participant.label
df <- merge(df, comment_subset, by = 'participant_label', all.x = T)

# ordering the data frame
df <- df %>% arrange(sequential_ID)
```

## 1.5 Defining functions to extract variables from the page time data ('pagetimes' object)

We want to: 

- Extract the page times for each rating round and break round, for each participant
- Extract the total time spent in the online experiment + the rating flow of the experiment (is somewhat redundant since we have similar information in the data from Prolific)
- Append this information to the grand data frame

```{r}
# grouping and ordering the rows by participant
pagetimes <- pagetimes %>% group_by(participant_code) %>% arrange()

# making a copy of the data frame
pagetimes_filtered <- pagetimes

# finding the participant codes that appear in both data frames
match <- pagetimes_filtered$participant_code %in% data$participant.code 

# filtering out rows in pagetimes object without a match in the rating data frame
pagetimes_filtered <- pagetimes_filtered %>% 
  filter(participant_code %in% data$participant.code) %>% 
  group_by(participant_code) %>% 
  arrange(participant_code)

# making sure all page times are recorded for all participants
for (i in 1:length(unique(pagetimes_filtered$participant_code))) {
  pagetime_temp <- pagetimes_filtered %>% filter(participant_code == participant_code_list[i])
  if (length(pagetime_temp)<6) {
    print("missing data")
  } else { 
    print("all good")
    }
}

# changing to wide format
pagetimes_filtered <- pagetimes_filtered %>% 
  group_by() %>% 
  pivot_wider(
    id_cols = participant_code,
    names_from = c(round_number, page_name),
    values_from = epoch_time_completed,
    names_glue = "{round_number}_{page_name}"
)

# computing total time spent + time in rating pages / break pages (by row subtraction)
pagetimes_filtered <- pagetimes_filtered %>% 
  mutate(total_experiment_timespan = 
           (`5_FinalQuestions`-`1_InitializeParticipant`))

pagetimes_filtered <- pagetimes_filtered %>% 
  mutate(total_rating_flow_timespan = 
           (`5_Rating_modification_round_structure`-`1_Instruction_5`))

pagetimes_filtered <- pagetimes_filtered %>% 
  mutate(total_break_time = 
           ((`2_BreakPage`-`1_Rating_modification_round_structure`)+(`4_BreakPage`-`3_Rating_modification_round_structure`)))

pagetimes_filtered <- pagetimes_filtered %>% 
  mutate(total_rating_time = (total_rating_flow_timespan-total_break_time))

# making a subset with the above columns + participant_code
pagetimes_subset <- pagetimes_filtered %>% select(participant_code,
                                                  total_experiment_timespan, 
                                                  total_rating_flow_timespan,
                                                  total_rating_time,
                                                  total_break_time)

# merging this subset with the grand data frame the
df <- merge(df, pagetimes_subset, by = 'participant_code', all.x = T)
df <- df %>% arrange(sequential_ID)
```

```{r}
colnames(df)

table(df$passed_checks)
```

## 1.6 Writing data

```{r}
file_name = "pre_processed_data_stim_study_1_28_participants"
extension = ".csv"
path = paste0("/Users/christianstenbro/AU/eSYMb/Similarity Rating Exp/pre-processed_data_frames/", file_name, extension)

write_csv(df, file = path)
```

# 2. Statistics (in-progress)

```{r}
# grouping the data
df <- df %>% group_by(sequential_ID)

# adding study number variable
# df <- df %>% mutate(study_nymber = case_when((sequential_ID >= 1 & sequential_ID <= 4) ~ 1,
#                                              (sequential_ID >= 5 & sequential_ID <= 7) ~ 2,
#                                              (sequential_ID >= 8 & sequential_ID <= 10) ~ 3))

# reformating data types
df$image_ratings <- as.numeric(df$image_ratings)
df$attention_check_status_clean <- as.logical(df$attention_check_status_clean)


df_summary <- df %>% summarise('rt_median' = median(rating_times), 
                 'rt_sd' = sd(rating_times),
                 'rating_mean' = mean(image_ratings), 
                 'rating_sd' = sd(image_ratings),
                 'failed_att_checks' = sum(attention_check_status_clean == FALSE, na.rm = TRUE),
                 'total_rating_time_ms' = sum(rating_times),
                 'total_rating_time_min' = sum(rating_times)/1000/60)

# print the entire stat summary
df_summary

# computing aggregated stats
# mean of means study 3
# round(mean(df_summary$rt_median[1:4]), 1)
# round(mean(df_summary$rt_sd[1:4]), 1)
# round(mean(df_summary$rating_mean[1:4]), 1)
# round(mean(df_summary$rating_sd[1:4]), 1)
# 
# # mean of means study 2
# round(mean(df_summary$rt_median[5:7]), 1)
# round(mean(df_summary$rt_sd[5:7]), 1)
# round(mean(df_summary$rating_mean[5:7]), 1)
# round(mean(df_summary$rating_sd[5:7]), 1)
# 
# # mean of means study 1
# round(mean(df_summary$rt_median[8:10]), 1)
# round(mean(df_summary$rt_sd[8:10]), 1)
# round(mean(df_summary$rating_mean[8:10]), 1)
# round(mean(df_summary$rating_sd[8:10]), 1)
```
The stats are appended to the data frame

```{r}
df <- merge(df, df_summary, by = "sequential_ID", all = T)
```

# 3. Visualisation (in-progress)

```{r}
#visual_subset <- df %>% filter(failed_att_checks <= 2)
visual_subset <- df
```

```{r}
hist(visual_subset$image_ratings, 
     col = 1,
     main = "Stim from study 3: \nDistribution of ratings for the entire sample (n = 43)",
     xlab = "Rating")

simplehist(visual_subset$rating_times)

# plotting attention checks
color_var <- ifelse(att_check_subset$failed_checks > 1, "red", "blue")

plot(att_check_subset$passed_checks,
     xlab = "participant ID",
     ylab = "Passed attention checks",
     ylim = c(0,6),
     pch = 16,
     col = color_var,
     main = "Stim from study 3: \nAttention checks (n = 43)")
abline(h = 4, lty = 3)

table(att_check_subset$failed_checks > 1)
```

Plotting the total time spent in the experiment:

```{r}

row_pr_participant_subset <- visual_subset %>% group_by(participant_label) %>% slice_sample(n = 1)

plot(
  x = 1:nrow(row_pr_participant_subset),
  y = row_pr_participant_subset$total_experiment_timespan,
  type = "n",
  ylim = range(c(0,max(row_pr_participant_subset$total_experiment_timespan))),
  xlab = "Participant Index",
  ylab = "Time (in seconds)",
  main = "Stim from study 3: \nCompletion time overview (n = 43)"
)

abline(v = 1:nrow(row_pr_participant_subset), col = "lightgray", lty = "dotted")

points(
  x = 1:nrow(row_pr_participant_subset),
  y = row_pr_participant_subset$total_experiment_timespan,
  pch = 16, col = "blue"
)

points(
  x = 1:nrow(row_pr_participant_subset),
  y = row_pr_participant_subset$total_rating_time,
  pch = 16, col = "green"
)

points(
  x = 1:nrow(row_pr_participant_subset),
  y = row_pr_participant_subset$total_break_time,
  pch = 16, col = "orange"
)

legend("topleft", legend = c("Total time in experiment", "Rating time", "Break time"), col = c("blue", "green", "orange"), pch = 16, cex = 0.7)
```


```{r}
visual_subset$image_ratings <- as.numeric(visual_subset$image_ratings)
```


```{r}
simplehist(visual_subset$image_ratings)

# visualising the combined data frame
# making color scale for ratings
z <- as.numeric(visual_subset$image_ratings)
n_colors <- 100
color_indices <- as.numeric(cut(z, breaks = n_colors, include.lowest = TRUE))
point_colors_r <- viridis(n_colors)[color_indices]

# making color scale for rating times
z <- visual_subset$rating_times
n_colors <- 100
color_indices <- as.numeric(cut(z, breaks = n_colors, include.lowest = TRUE))
point_colors_rt <- viridis(n_colors)[color_indices]

# drawing plots for image ratings
jitt = rnorm(n = length(visual_subset$image_ratings),
             mean = 0, sd = 0.1)

plot(x = visual_subset$image_indices,
     y = visual_subset$image_ratings + jitt,
     col = col.alpha(rangi2, 0.1),
     pch = 19,
     main = "Stim from study 3: \nratings x indices (n = 43, jittered)",
     xlab = "index", ylab = "similarity rating (numeric)")

# adding stats
#abline(h = df_summary$rating_mean, col = df_summary$sequential_ID)

# drawing rating time plot
plot(x = visual_subset$image_indices,
     y = visual_subset$rating_times,
     col = visual_subset$round_number, 
     pch = 19,
     main = "Stim from study 3: \nRating times x Indices (n = 43, cut at 20 sec.)",
     xlab = "index", ylab = "rating time (mili seconds)",
     ylim = c(0,200000)
     )

```

```{r}
# trying to visualize this stuff
library(viridis)

# making color scale for ratings
z <- as.numeric(subset_unpacked$image_ratings)
n_colors <- 100
color_indices <- as.numeric(cut(z, breaks = n_colors, include.lowest = TRUE))
point_colors_r <- viridis(n_colors)[color_indices]

# making color scale for rating times
z <- subset_unpacked$rating_times
n_colors <- 100
color_indices <- as.numeric(cut(z, breaks = n_colors, include.lowest = TRUE))
point_colors_rt <- viridis(n_colors)[color_indices]

# drawing plots
plot(x = subset_unpacked$image_indices,
     y = subset_unpacked$image_ratings,
     col = point_colors_r,
     pch = 19,
     main = "ratings x indices",
     xlab = "index", ylab = "similarity rating (numeric)")

plot(x = subset_unpacked$image_indices,
     y = subset_unpacked$rating_times,
     col = point_colors_rt,
     pch = 19,
     main = "rating times x indices",
     xlab = "index", ylab = "rating time (mili seconds)",
     ylim = c(0,50000))
```

